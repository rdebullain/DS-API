{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data from the CSV file\n",
    "final_df_clean = pd.read_csv('cleaned_bike_stations_pois.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "target = 'number_of_bikes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "final_df_encoded = pd.get_dummies(final_df_clean, columns=['poi_price', 'poi_category', 'source'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all numeric and one-hot encoded features dynamically\n",
    "all_features = [col for col in final_df_encoded.columns if col.startswith(('poi_price_', 'poi_category_', 'source_'))] + ['poi_rating', 'poi_latitude', 'poi_longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any features selected\n",
    "if not all_features:\n",
    "    raise ValueError(\"No features selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to numeric\n",
    "X = final_df_encoded[all_features].apply(pd.to_numeric, errors='coerce')\n",
    "y = pd.to_numeric(final_df_encoded[target], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any columns in X that couldn't be converted to numeric data\n",
    "X = X.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with missing values in features or target\n",
    "missing_rows = X.isna().any(axis=1) | y.isna()\n",
    "X = X.loc[~missing_rows]\n",
    "y = y.loc[~missing_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for sufficient data\n",
    "if len(X) < len(X.columns):\n",
    "    raise ValueError(\"Not enough data to fit the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term for the OLS model\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the OLS regression model\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        number_of_bikes   R-squared:                       0.116\n",
      "Model:                            OLS   Adj. R-squared:                  0.111\n",
      "Method:                 Least Squares   F-statistic:                     26.34\n",
      "Date:                Tue, 07 May 2024   Prob (F-statistic):           5.06e-16\n",
      "Time:                        21:22:37   Log-Likelihood:                -2163.6\n",
      "No. Observations:                 607   AIC:                             4335.\n",
      "Df Residuals:                     603   BIC:                             4353.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const          3481.4418    475.983      7.314      0.000    2546.655    4416.228\n",
      "poi_rating       -0.1669      0.160     -1.042      0.298      -0.482       0.148\n",
      "poi_latitude    -59.4988     12.335     -4.824      0.000     -83.723     -35.275\n",
      "poi_longitude   -43.3587      6.803     -6.373      0.000     -56.720     -29.997\n",
      "==============================================================================\n",
      "Omnibus:                       53.718   Durbin-Watson:                   0.143\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               66.436\n",
      "Skew:                           0.808   Prob(JB):                     3.75e-15\n",
      "Kurtosis:                       3.135   Cond. No.                     6.49e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.49e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **R-squared**: The R-squared value of 0.116 indicates that only about 11.5% of the variation in the number of bikes can be explained by the model. This means that the model, as it currently stands, does not explain a large portion of the variation in the number of bikes. There may be other variables not included in the model that could help explain the number of bikes.\n",
    "\n",
    "2. **Adjusted R-squared**: The adjusted R-squared is 0.111, which is slightly less than the R-squared value of 0.116. This indicates that some of the predictors in the model do not significantly improve the model's ability to predict the dependent variable, `number_of_bikes`.\n",
    "\n",
    "3. **Coefficients**: The coefficients tell us about the relationship between the predictors (poi_rating, poi_latitude, poi_longitude) and the response variable (number_of_bikes).\n",
    "\n",
    "   - `poi_rating`: The coefficient of -0.1669 suggests that for each unit increase in poi_rating, the number of bikes decreases by about 0.2175, assuming all other variables are held constant. However, the p-value for this variable is 0.298, which is greater than 0.05, suggesting that the effect of poi_rating on the number of bikes is not statistically significant at the 5% level.\n",
    "   \n",
    "   - `poi_latitude`: The coefficient of -59.2988 suggests that for each unit increase in poi_latitude, the number of bikes decreases by about 59, assuming all other variables are held constant. The p-value for this variable is less than 0.05, suggesting that the effect of poi_latitude on the number of bikes is statistically significant at the 5% level.\n",
    "   \n",
    "   - `poi_longitude`: The coefficient of -43.3587 suggests that for each unit increase in poi_longitude, the number of bikes decreases by about 43, assuming all other variables are held constant. The p-value for this variable is less than 0.05, suggesting that the effect of poi_longitude on the number of bikes is statistically significant at the 5% level.\n",
    "\n",
    "4. **F-statistic**: The F-statistic is used to test whether at least one predictor variable has a non-zero coefficient. In this case, the p-value of the F-statistic is very small (5.06e-16), suggesting that at least one of the predictors is statistically significant.\n",
    "\n",
    "In summary, the model suggests that `poi_latitude` and `poi_longitude` have a significant impact on the `number_of_bikes`, while `poi_rating` does not. However, the model only explains about 11.5% of the variation in the number of bikes, and there are potential issues with autocorrelation and multicollinearity that may need to be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you turn the regression model into a classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data from the CSV file\n",
    "df = pd.read_csv('cleaned_bike_stations_pois.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and it includes your target 'number_of_bikes' and features 'poi_rating', 'poi_latitude', 'poi_longitude'\n",
    "df['is_high'] = df['number_of_bikes'].apply(lambda x: 1 if x > 20 else 0)\n",
    "\n",
    "X = df[['poi_rating', 'poi_latitude', 'poi_longitude']]\n",
    "y = df['is_high']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use clf to predict whether the number of bikes is high or not\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.860655737704918\n",
      "Precision: 0.7142857142857143\n",
      "Recall: 0.25\n",
      "F1 Score: 0.37037037037037035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the metrics used to evaluate the performance of the classification model:\n",
    "\n",
    "1. **Accuracy**: This is the ratio of correct predictions to the total number of predictions. An accuracy of 0.86 means that the model correctly predicted the class 86% of the time. This is a general measure of how often the classifier is correct.\n",
    "\n",
    "2. **Precision**: This is the ratio of true positive predictions to the total number of positive predictions (true positives + false positives). A precision of 0.71 means that when the model predicts the positive class, it is correct 71% of the time. Precision is a measure of how many of the positive predictions were actually correct.\n",
    "\n",
    "3. **Recall (Sensitivity)**: This is the ratio of true positive predictions to the total number of actual positives (true positives + false negatives). A recall of 0.25 means that the model correctly identifies 25% of all actual positive instances. Recall is a measure of how many of the actual positive instances the model is able to identify.\n",
    "\n",
    "4. **F1 Score**: This is the harmonic mean of precision and recall, and it tries to balance the two. An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. The F1 score is 0.37, which is relatively low, indicating that the model's precision and recall are not well balanced.\n",
    "\n",
    "In summary, the model has high accuracy but low recall and a low F1 score. This suggests that while the model is correct a high percentage of the time, it's not doing a great job at identifying positive instances (it's missing a lot of positive instances). The low F1 score suggests that the model's precision and recall are not well balanced. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
